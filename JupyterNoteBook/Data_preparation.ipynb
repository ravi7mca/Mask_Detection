{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preparation\n",
    "Face detection using OpenCV DNN face detector\n",
    "\"\"\"\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "base_dir = os.path.join(Path.home(), \"Mask_Detection\")\n",
    "raw_data_path = os.path.join(base_dir, \"RawData\")\n",
    "train_data_path = os.path.join(base_dir, \"train\")\n",
    "\n",
    "# Data Augmentation only on training data \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,\n",
    "                                                            zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "original_image_path = os.path.join(raw_data_path, \"raw_training_data\\Mask\")\n",
    "augmented_image_path = os.path.join(raw_data_path, \"raw_training_data\\AugmentedMaskData\")\n",
    "\n",
    "if not os.path.exists(augmented_image_path):\n",
    "    os.mkdir(augmented_image_path)\n",
    "else:\n",
    "    [os.remove(os.path.join(augmented_image_path, f)) for f in os.listdir(augmented_image_path)]\n",
    "               \n",
    "# first copy all original images from original directory to other directory \n",
    "for index, file in enumerate(os.listdir(original_image_path), start=1):\n",
    "    shutil.copy(os.path.join(original_image_path,file), os.path.join(augmented_image_path, file))\n",
    "\n",
    "fname = [os.path.join(augmented_image_path, file) for file in os.listdir(augmented_image_path)]\n",
    "\n",
    "for index, img_path in enumerate(fname, start=1):\n",
    "    img = image.load_img(img_path, target_size=(300,300))\n",
    "    x = image.img_to_array(img)\n",
    "    #Reshapes it to (1, 200, 200, 3)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1):\n",
    "        newImage = image.array_to_img(batch[0])\n",
    "        fileName = \"augmented_Mask_\" + str(index) + \"_\" + str(i) + \".jpg\"\n",
    "        newImage.save(os.path.join(augmented_image_path, fileName))\n",
    "        #print(x)\n",
    "        i += 1\n",
    "        if i % 3 == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the augmented image to traing directory\n",
    "raw_training_data_path = os.path.join(raw_data_path, \"training_data\\Mask\")\n",
    "\n",
    "if not os.path.exists(raw_training_data_path):\n",
    "    os.mkdir(raw_training_data_path)\n",
    "else:\n",
    "    [os.remove(os.path.join(raw_training_data_path, f)) for f in os.listdir(raw_training_data_path)]\n",
    "    \n",
    "for index, file in enumerate(os.listdir(augmented_image_path), start=1):\n",
    "    shutil.move(os.path.join(augmented_image_path,file), os.path.join(raw_training_data_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model:\n",
    "net = cv.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "def data_processing(raw_data_path, processed_data_path, conf):      \n",
    "    for fold in os.listdir(raw_data_path):\n",
    "        inputPath = os.path.join(raw_data_path, fold)\n",
    "        savePath = os.path.join(processed_data_path, fold)\n",
    "        if not os.path.exists(savePath):\n",
    "            os.mkdir(savePath)\n",
    "        for file in os.listdir(inputPath):      \n",
    "            # Load image:\n",
    "            image = cv.imread(os.path.join(inputPath, file))\n",
    "\n",
    "            # Get dimensions of the input image (to be used later):\n",
    "            (h, w) = image.shape[:2]\n",
    "\n",
    "            # Create 4-dimensional blob from image:\n",
    "            blob = cv.dnn.blobFromImage(image, 1.0, (300, 300), [104., 117., 123.], False, False)\n",
    "\n",
    "            # Set the blob as input and obtain the detections:\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "\n",
    "            # Initialize the number of detected faces counter detected_faces:\n",
    "            detected_faces = 0\n",
    "\n",
    "            # Iterate over all detections:\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                # Get the confidence (probability) of the current detection:\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                # Only consider detections if confidence is greater than a fixed minimum confidence:\n",
    "                if confidence > conf:\n",
    "                    # Increment the number of detected faces:\n",
    "                    detected_faces += 1\n",
    "                    # Get the coordinates of the current detection:\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                    roi = image[(startY): endY, (startX): endX]\n",
    "                    #roiimage = cv2.resize(roi, (200, 200))\n",
    "                    filename = str(os.path.join(savePath, file)).split('.')[0] + \".jpg\"\n",
    "                    #print(filename)\n",
    "                    cv.imwrite(filename, roi)\n",
    "                    \n",
    "def delete_dirs(root_dir_path):\n",
    "    for filename in os.listdir(root_dir_path):\n",
    "        file_path = os.path.join(root_dir_path, filename)\n",
    "        try:\n",
    "            if os.path.exists(file_path) and (os.path.isfile(file_path) or os.path.islink(file_path)):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets process the training data\n",
    "raw_training_data_path = os.path.join(raw_data_path, \"training_data\")\n",
    "delete_dirs(train_data_path)\n",
    "data_processing(raw_training_data_path, train_data_path, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets process the validation data\n",
    "validation_data_path = os.path.join(base_dir, \"validation\")\n",
    "delete_dirs(validation_data_path)\n",
    "        \n",
    "\"\"\"for dire in os.listdir(train_data_path):\n",
    "    label_path = os.path.join(train_data_path, dire)\n",
    "    savePath = os.path.join(validation_data_path, dire)\n",
    "    if not os.path.exists(savePath):\n",
    "        os.mkdir(savePath)\n",
    "    for index, file in enumerate(os.listdir(label_path), start=1):\n",
    "        if index < 200:\n",
    "            shutil.move(os.path.join(label_path,file), os.path.join(savePath, file))\"\"\"\n",
    "\n",
    "raw_validation_data_path = os.path.join(raw_data_path, \"validation\")\n",
    "delete_dirs(validation_data_path)\n",
    "data_processing(raw_validation_data_path, validation_data_path, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
